\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Neural Networks}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Derivation of the derivative of the transfer function}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A simple neural network. Nodes with 1 use for biases}}{1}}
\newlabel{graph}{{1}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Neural Network Training}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Using 20 neurons, 10000 iterations, and a learning rate of 0.01, neural networks learn the underlying distribution. Further, we see no evidence of overfitting, despite not using early stopping}}{3}}
\newlabel{goodplot}{{2}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Support Vector Machines}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Model Selection Using Grid Search}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Inspecting the Kernel Expansion}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Visualizing the SVM solution}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  Bound vectors represented in black. Unbound vectors are clear }}{5}}
\newlabel{bound}{{3}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Effect of the Regularization Parameter}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces visualization with $\gamma =1$ and $C=0.001$ }}{6}}
\newlabel{smallC}{{4}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces visualization with $\gamma =1$ and $C=100$ }}{7}}
\newlabel{bigC}{{5}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Scaling Behavior}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces bound, unbound, and total vectors, at different observations and different values of C}}{8}}
\newlabel{SVectors}{{6}{8}}
